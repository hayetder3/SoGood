import pyarrow.dataset as ds
import pandas as pd

print("\nüöÄ OUVERTURE Parquet en mode STREAMING avec PyArrow...")

# 1Ô∏è‚É£ Charger dataset PyArrow
dataset = ds.dataset('data/parquet/food.parquet', format='parquet')

# 2Ô∏è‚É£ Cr√©er le scanner CORRECT
scanner = dataset.scanner(columns=['code', 'product_name', 'brands', 'categories',
                                   'nutriscore_grade', 'nova_group', 'nutriments'])

# 3Ô∏è‚É£ Pr√©parer CSV output
output_csv = 'data/processed/SoGood_from_Parquet.csv'
first_batch = True

# 4Ô∏è‚É£ Parcourir par batch
for batch in scanner.to_batches():
    df = batch.to_pandas()

    # === Extraire product_name
    def extract_product_name(x):
        try:
            for d in x:
                if d.get('lang') == 'main':
                    return d.get('text')
        except:
            return None

    df['product_name_clean'] = df['product_name'].apply(extract_product_name)

    # === Extraire nutriments
    def parse_nutriments(nlist, key):
        try:
            for d in nlist:
                if d.get('name') == key:
                    return d.get('100g')
            return None
        except:
            return None

    keys = ['energy-kcal', 'fat', 'sugars', 'salt', 'proteins']
    for k in keys:
        df[f"{k}_100g"] = df['nutriments'].apply(lambda x: parse_nutriments(x, k))

    keep = ['code', 'product_name_clean', 'brands', 'categories',
            'nutriscore_grade', 'nova_group'] + [f"{k}_100g" for k in keys]

    final = df[keep]

    # === Sauvegarder en mode append
    if first_batch:
        final.to_csv(output_csv, index=False, mode='w')
        first_batch = False
    else:
        final.to_csv(output_csv, index=False, mode='a', header=False)

    print(f"‚úÖ Batch √©crit : {len(final)} lignes...")

print("\nüéâ CSV FINAL propre g√©n√©r√© sans crash RAM üöÄ‚ú®")
